<div align='center'>


# ✨ Mac Ollama Client ✨

_Ollama-based LLM Mac client_

[ENGLISH](README.md) •
[한국어](README_KR.md) •
[日本語](README_JP.md) •
[中文](README_CH.md)

</div>

# MacOllama

MacOllama 是一款 Mac 客户端应用程序，可让您连接到已安装 Ollama 的计算机，并与大型语言模型（LLM）进行交互。您可以从 [Apple App Store](https://apps.apple.com/us/app/mac-ollama-client/id6741420139) 下载并构建源代码或下载 MacOllama 应用程序。

## 引言

Ollama 是一款开源软件，可让您在本地计算机上轻松运行大型语言模型 (LLM)。
您可以使用 MacOllama 访问 Ollama 并使用各种 LLM。MyOllama - 通过 Ollama 程序在您自己的计算机上运行大型语言模型，这样您就可以与人工智能模型对话而无需支付费用。

![poster](image_en.jpg)

## Key features

- Local LLM access： 连接本地 LLM http://localhost:11434
- 远程 LLM 访问： 自定义提示：支持设置自定义指令 - 支持
各种开源 LLM（Deepseek、Llama、Gemma、Qwen、Mistral 等）
- 可自定义指令设置
- 支持图像识别（仅在支持图像识别的模型上）
- 直观的聊天式用户界面 -
 对话历史：保存和管理聊天会话
- 支持韩语、英语、日语、中文 - 支持
 Markdown 格式

![poster](image_settings.jpg)

## 使用方法

1. 在电脑上安装 Ollama（支持 macOS、Windows 和 Linux）。你可以在 [Ollama GitHub](https://ollama.com/download) 上查看如何安装 Ollama。
2. 下载源代码并用 Xcode 构建，或从 [App Store](https://apps.apple.com/us/app/my-ollama/id6738298481) 下载 MyOllama 应用程序。
3. 在 Ollama 中安装所需的模型。[下载模型](https://ollama.com/search)
4. 更改设置以远程访问 Ollama。请参阅： [链接](http://practical.kr/?p=809) 
5. 启动 MyOllama 应用程序并输入安装有 Ollama 的计算机的 IP 地址。
6. 选择所需的人工智能模型并开始对话。

## 系统要求

- 此应用程序专为希望有效利用开源 LLM 的开发人员和研究人员设计。它可用于各种技术实验，如 API 调用、提示工程、模型性能测试等。
- 免费提供先进的人工智能功能
- 支持多种 LLM 模型
- 隐私保护（在本地机器上运行）
- 适用于编程、创意工作、随意提问等多种用途。
- 根据上下文组织对话


## 注意

- 本应用程序需要一台安装了 Ollama 的电脑。
- 您有责任设置和管理您的 Ollama 主机。请注意安全设置。

## 下载应用程序 

- 如果您在构建应用程序时遇到困难，可从以下链接下载应用程序。
-[https://apps.apple.com/us/app/mac-ollama-client/id6741420139](https://apps.apple.com/us/app/mac-ollama-client/id6741420139)

### 许可证

MyOllama 采用 GNU 许可证。有关详细信息，请参阅 [LICENSE](LICENSE) 文件。

## 联系

有关 MyOllama 的问题或错误报告，请发送电子邮件至 rtlink.park@gmail.com。