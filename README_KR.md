<div align='center'>


# ✨ LLM Hippo - 올라마 클라이언트 ✨

_Ollama-based LLM Mac client_

[ENGLISH](README.md) •
[한국어](README_KR.md) •
[日本語](README_JP.md) •
[中文](README_CH.md)

</div>

#  LLM Hippo

LLM Hippo Ollama가 설치된 컴퓨터에 연결하여 대규모 언어 모델(LLM)과 상호 작용할 수 있는 Mac 클라이언트 앱입니다. 소스 코드를 다운로드하여 빌드하거나 [Apple App Store](https://apps.apple.com/us/app/mac-ollama-client/id6741420139)에서 LLM Hippo 앱을 다운로드할 수 있습니다.

##  소개

Ollama는 로컬 컴퓨터에서 대규모 언어 모델(LLM)을 쉽게 실행할 수 있는 오픈 소스 소프트웨어입니다.
LLM Hippo 사용하여 Ollama에 액세스하고 다양한 LLM을 활용할 수 있습니다. MyOllama - Ollama 프로그램을 통해 자신의 컴퓨터에서 LLM을 실행하여 유료 요금 없이 AI 모델과 대화할 수 있습니다.

![포스터](image_en.jpg)

## 주요 기능

- 로컬 LLM 액세스: 로컬 LLM 연결 http://localhost:11434
- 원격 LLM 액세스: IP 주소를 통해 올라마 호스트에 연결
- 사용자 지정 프롬프트: 사용자 지정 명령어 설정 지원
- 다양한 오픈 소스 LLM(Deepseek, Llama, Gemma, Qwen, Mistral 등) 지원
- 사용자 지정 LLM 지침 설정
- 이미지 인식 지원(지원하는 모델에 한함) 
- 직관적인 채팅형 UI
- 대화 기록: 채팅 세션 저장 및 관리
- 한국어, 영어, 일본어, 중국어 지원
- 마크다운 형식 지원

![poster](image_settings.jpg)

##  사용 방법

1. 컴퓨터에 올라마를 설치합니다(맥OS, 윈도우, 리눅스 지원). 올라마 설치 방법은 [올라마 깃허브](https://ollama.com/download)에서 확인할 수 있습니다.
2. 소스를 다운로드하여 Xcode로 빌드하거나 [앱스토어](https://apps.apple.com/us/app/my-ollama/id6738298481)에서 MyOllama 앱을 다운로드합니다.
3. 올라마에 원하는 모델을 설치합니다. [모델 다운로드](https://ollama.com/search)
4. 올라마에서 원격으로 액세스할 수 있도록 설정을 변경합니다. 참조: [링크](http://practical.kr/?p=809) 
5. MyOllama 앱을 실행하고 Ollama가 설치된 컴퓨터의 IP 주소를 입력합니다.
6. 원하는 AI 모델을 선택하고 대화를 시작합니다.

##  시스템 요구사항

- 올라마가 설치된 컴퓨터
- 네트워크 연결

## 장점

- 오픈소스 LLM을 효율적으로 활용하고자 하는 개발자 및 연구자를 위해 설계된 앱입니다. API 호출, 프롬프트 엔지니어링, 모델 성능 테스트 등 다양한 기술 실험에 활용할 수 있습니다.
-  무료로 제공되는 고급 AI 기능
- 다양한 LLM 모델 지원
- 개인정보 보호(로컬 컴퓨터에서 실행)
- 프로그래밍, 창작 작업, 일상적인 질문 등에 다용도로 사용 가능.
-  대화 내용을 맥락에 맞게 정리

## 참고사항

- 이 앱을 사용하려면 Ollama가 설치된 컴퓨터가 필요합니다.
- 올라마 호스트를 설정하고 관리할 책임은 사용자 본인에게 있습니다. 보안 설정에 유의하세요.

##  앱 다운로드 

- 구축에 어려움을 겪는 분들은 아래 링크에서 앱을 다운로드할 수 있습니다.
- [https://apps.apple.com/us/app/mac-ollama-client/id6741420139](https://apps.apple.com/us/app/mac-ollama-client/id6741420139)

## 라이선스

MyOllama는 GNU 라이선스에 따라 라이선스가 부여됩니다. 자세한 내용은 [LICENSE](라이선스) 파일을 참조하세요.

## 연락처

MyOllama에 대한 질문이나 버그 신고는 rtlink.park@gmail.com 으로 이메일을 보내주세요.

